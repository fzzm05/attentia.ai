# attentia.ai ğŸ§   
**attention.ai** is a web-based AI platform designed to help individuals with cognitive and neurodevelopmental disabilities improve focus and engagement while studying.

The platform continuously infers user attention by combining signals from:

- ğŸ“· **Camera input** â€” to detect facial cues and emotional states  
- ğŸ¤ **Microphone input** â€” to detect disturbances, background noise, and audio patterns  

These multimodal signals are processed by a **custom reinforcement learning (RL) model**, which evaluates whether the user is focused or distracted in real time.

Based on the inferred state, the system dynamically:
- Identifies the type and level of distraction  
- Determines whether attention has drifted  
- Prompts the user with adaptive interventions  
- Suggests changes in study behavior or environment  

The goal is not surveillance, but supportive guidance â€” helping users gently re-orient their attention in a way that is personalized, explainable, and non-intrusive.

## Goal

To provide an accessible, intelligent, and adaptive focus-assistance system that empowers individuals with cognitive disabilities to study more effectively and independently.


## ğŸ“ Project Structure

```text
ATTENTIA.AI/
â”œâ”€â”€ data/                    # Local data storage (ignored by git)
â”œâ”€â”€ docs/                    # Documentation files
â”‚   â””â”€â”€ guide.md
â”œâ”€â”€ scripts/                 # Entry point scripts for execution
â”‚   â””â”€â”€ run_audio_monitor.py
â”œâ”€â”€ src/                     # Main source code directory
â”‚   â””â”€â”€ attentia_ai/
â”‚       â”œâ”€â”€ helpers/         # Utility and processing modules
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ config.py
â”‚       â”‚   â”œâ”€â”€ dsp.py
â”‚       â”‚   â””â”€â”€ emotion.py
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ audio_monitor.py
â”œâ”€â”€ .gitignore               # Files to exclude from version control
â”œâ”€â”€ pyproject.toml           # Build system and project metadata
â”œâ”€â”€ README.md                # Project overview and instructions
â””â”€â”€ requirements.txt         # List of dependencies
```        

## ğŸš€ How to Run

### 1. Activate virtual environment
```bash
source .venv/bin/activate
```
### 2. Install dependencies
```bash
source pip install -r requirements.txt
```
### 3. Run the audio monitor
```bash
source PYTHONPATH=src python scripts/run_audio_monitor.py
```

Press Ctrl + C to stop.

## Dependencies (so far)

- Python 3.10+
- numpy
- sounddevice

## Intended Use Cases

- Attention and focus research
- Behavioral signal analysis
- Feature generation for ML pipelines
- Reinforcement learning state inputs
- Lightweight real-time monitoring

## Future Extensions

- Emotion inference models
- Speech vs noise classification
- Camera-based attention signals
- Reinforcement learning feedback loops
- Dataset logging and replay
- API / service mode
- Embedded / Raspberry Pi deployment